version: 0.1.0
type: SERVICE
metadata:
  name: "ollama"
  displayName: "ollama"
  description: "DeepSeek Coder API with OLLAMA integration"
  icon: "https://raw.githubusercontent.com/wso2/choreo-samples/main/icons/python.png"
  tags:
    - "ai"
    - "code-generation"
    - "ollama"
    - "deepseek"

build:
  type: dockerfile
  dockerfile: Dockerfile
  context: .
  dockerPort: 8000

deploy:
  restApi:
    apiType: REST
    port: 8000
    context: /
    basePath: /
    production:
      replicas: 1
      resources:
        requests:
          cpu: "0.5"
          memory: "512Mi"
        limits:
          cpu: "1"
          memory: "1Gi"
    cors:
      enabled: true
      allowOrigins:
        - "*"
    security:
      enabled: true
      authTypes:
        - OAuth2
    endpoints:
      - name: "Health Check"
        basePath: /health
        secured: false
        operations:
          - target: /health
            verb: GET
            secured: false
            summary: "Health check endpoint"
      - name: "Model Info"
        basePath: /api/v1/model
        operations:
          - target: /api/v1/model
            verb: GET
            secured: true
            summary: "Get model information"
      - name: "Code Generation"
        basePath: /api/v1/generate
        operations:
          - target: /api/v1/generate
            verb: POST
            secured: true
            summary: "Generate code using DeepSeek Coder"

configs:
  env:
    - name: OLLAMA_API_BASE_URL
      required: true
      defaultValue: "http://localhost:11434"
    - name: OLLAMA_MODEL_NAME
      required: true
      defaultValue: "deepseek-coder"
    - name: REQUEST_TIMEOUT
      required: false
      defaultValue: "300"
    - name: RATE_LIMIT_PER_MINUTE
      required: false
      defaultValue: "60" 