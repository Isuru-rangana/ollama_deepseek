version: 1.0.0
type: REST_API
buildSpec:
  env: docker
  builder: default
  buildCommand: docker build -t ollama-deepseek-api .
metadata:
  name: ollama-deepseek
  displayName: Ollama DeepSeek API
  description: DeepSeek Coder API with OLLAMA integration
  icon: https://raw.githubusercontent.com/wso2/choreo-samples/main/icons/python.png
  labels:
    - ai
    - code-generation
    - ollama
    - deepseek
    - python
    - rest-api
deploySpec:
  replicas: 1
  envs:
    - name: OLLAMA_API_BASE_URL
      value: "http://your-ollama-service:11434"  # This needs to be updated to your actual OLLAMA service URL
    - name: OLLAMA_MODEL_NAME
      value: "deepseek-coder"
    - name: REQUEST_TIMEOUT
      value: "300"
    - name: RATE_LIMIT_PER_MINUTE
      value: "60"
  containers:
    - image: ollama-deepseek-api
      name: main
      ports:
        - containerPort: 8080
          name: http
          protocol: TCP
      resources:
        requests:
          cpu: "0.5"
          memory: "512Mi"
        limits:
          cpu: "1.0"
          memory: "1Gi"